{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas\n",
    " \n",
    "os.environ[\"SPARK_HOME\"] = \"/usr/hdp/current/spark2-client\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "# In below two lines, use /usr/bin/python2.7 if you want to use Python 2\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/local/anaconda/bin/python\" \n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"/usr/local/anaconda/bin/python\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/py4j-0.10.4-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/pyspark.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up spark context and SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark regression example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the Dataset\n",
    "df = spark.read.format('com.databricks.spark.csv').\\\n",
    "                       options(header='true', \\\n",
    "                       inferschema='true').\\\n",
    "            load(\"file:///home/mofasafa6802/cloudxlab_jupyter_notebooks/USA_Housing.csv\",header=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+----------------+-------------------+---------------+-----------+\n",
      "|Area Income|Area House Age|Area No of Rooms|Area No of Bedrooms|Area Population|      Price|\n",
      "+-----------+--------------+----------------+-------------------+---------------+-----------+\n",
      "|79545.45857|   5.682861322|     7.009188143|               4.09|     23086.8005|1059033.558|\n",
      "|79248.64245|   6.002899808|     6.730821019|               3.09|    40173.07217|1505890.915|\n",
      "|61287.06718|    5.86588984|      8.51272743|               5.13|     36882.1594|1058987.988|\n",
      "|63345.24005|   7.188236095|     5.586728665|               3.26|    34310.24283|1260616.807|\n",
      "|59982.19723|   5.040554523|     7.839387785|               4.23|    26354.10947|630943.4893|\n",
      "|80175.75416|   4.988407758|     6.104512439|               4.04|    26748.42842|1068138.074|\n",
      "|64698.46343|   6.025335907|     8.147759585|               3.41|    60828.24909|1502055.817|\n",
      "|78394.33928|   6.989779748|     6.620477995|               2.42|    36516.35897|1573936.564|\n",
      "|59927.66081|    5.36212557|     6.393120981|                2.3|      29387.396|798869.5328|\n",
      "|81885.92718|    4.42367179|     8.167688003|                6.1|    40149.96575|1545154.813|\n",
      "+-----------+--------------+----------------+-------------------+---------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of cells in column Area Income with null values: 0\n",
      "no. of cells in column Area House Age with null values: 0\n",
      "no. of cells in column Area No of Rooms with null values: 0\n",
      "no. of cells in column Area No of Bedrooms with null values: 0\n",
      "no. of cells in column Area Population with null values: 0\n",
      "no. of cells in column Price with null values: 0\n"
     ]
    }
   ],
   "source": [
    "#Checking for Null Values\n",
    "\n",
    "for col in df.columns:\n",
    "    print(\"no. of cells in column\", col, \"with null values:\", df.filter(df[col].isNull()).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Area Income: double (nullable = true)\n",
      " |-- Area House Age: double (nullable = true)\n",
      " |-- Area No of Rooms: double (nullable = true)\n",
      " |-- Area No of Bedrooms: double (nullable = true)\n",
      " |-- Area Population: double (nullable = true)\n",
      " |-- Price: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Data exploration\n",
    "df.columns\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+-------------------+-----------------+------------------+\n",
      "|summary|       Area Income|    Area House Age|  Area No of Rooms|Area No of Bedrooms|  Area Population|             Price|\n",
      "+-------+------------------+------------------+------------------+-------------------+-----------------+------------------+\n",
      "|  count|              5000|              5000|              5000|               5000|             5000|              5000|\n",
      "|   mean| 68583.10898397019| 5.977222035287008| 6.987791850909204| 3.9813299999999967|36163.51603854035|1232072.6541452995|\n",
      "| stddev|10657.991213888685|0.9914561798324225|1.0058332312754115| 1.2341372654846832|9925.650113546026| 353117.6265836953|\n",
      "|    min|       17796.63119|       2.644304186|       3.236194023|                2.0|      172.6106863|       15938.65792|\n",
      "|    max|       107701.7484|       9.519088066|       10.75958834|                6.5|      69621.71338|       2469065.594|\n",
      "+-------+------------------+------------------+------------------+-------------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Perform descriptive analytics\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>summary</td>\n",
       "      <td>count</td>\n",
       "      <td>mean</td>\n",
       "      <td>stddev</td>\n",
       "      <td>min</td>\n",
       "      <td>max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Area Income</td>\n",
       "      <td>5000</td>\n",
       "      <td>68583.10898397019</td>\n",
       "      <td>10657.991213888685</td>\n",
       "      <td>17796.63119</td>\n",
       "      <td>107701.7484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Area House Age</td>\n",
       "      <td>5000</td>\n",
       "      <td>5.977222035287008</td>\n",
       "      <td>0.9914561798324225</td>\n",
       "      <td>2.644304186</td>\n",
       "      <td>9.519088066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Area No of Rooms</td>\n",
       "      <td>5000</td>\n",
       "      <td>6.987791850909204</td>\n",
       "      <td>1.0058332312754115</td>\n",
       "      <td>3.236194023</td>\n",
       "      <td>10.75958834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Area No of Bedrooms</td>\n",
       "      <td>5000</td>\n",
       "      <td>3.9813299999999967</td>\n",
       "      <td>1.2341372654846832</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Area Population</td>\n",
       "      <td>5000</td>\n",
       "      <td>36163.51603854035</td>\n",
       "      <td>9925.650113546026</td>\n",
       "      <td>172.6106863</td>\n",
       "      <td>69621.71338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Price</td>\n",
       "      <td>5000</td>\n",
       "      <td>1232072.6541452995</td>\n",
       "      <td>353117.6265836953</td>\n",
       "      <td>15938.65792</td>\n",
       "      <td>2469065.594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0                   1                   2  \\\n",
       "summary              count                mean              stddev   \n",
       "Area Income           5000   68583.10898397019  10657.991213888685   \n",
       "Area House Age        5000   5.977222035287008  0.9914561798324225   \n",
       "Area No of Rooms      5000   6.987791850909204  1.0058332312754115   \n",
       "Area No of Bedrooms   5000  3.9813299999999967  1.2341372654846832   \n",
       "Area Population       5000   36163.51603854035   9925.650113546026   \n",
       "Price                 5000  1232072.6541452995   353117.6265836953   \n",
       "\n",
       "                               3            4  \n",
       "summary                      min          max  \n",
       "Area Income          17796.63119  107701.7484  \n",
       "Area House Age       2.644304186  9.519088066  \n",
       "Area No of Rooms     3.236194023  10.75958834  \n",
       "Area No of Bedrooms          2.0          6.5  \n",
       "Area Population      172.6106863  69621.71338  \n",
       "Price                15938.65792  2469065.594  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().toPandas().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation to Price for  Area Income 0.6397337782571293\n",
      "Correlation to Price for  Area House Age 0.452542537178579\n",
      "Correlation to Price for  Area No of Rooms 0.3356644533593983\n",
      "Correlation to Price for  Area No of Bedrooms 0.1710710276560539\n",
      "Correlation to Price for  Area Population 0.40855587932093074\n",
      "Correlation to Price for  Price 1.0\n"
     ]
    }
   ],
   "source": [
    "# Find Co-relation X Variables with Y\n",
    "import six\n",
    "for i in df.columns:\n",
    "    if not( isinstance(df.select(i).take(1)[0][0], six.string_types)):\n",
    "        print( \"Correlation to Price for \", i, df.stat.corr('Price',i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the data to dense vector (features and label)\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.linalg import Vectors\n",
    "def transData(data):\n",
    "    return data.rdd.map(lambda r: [Vectors.dense(r[:-1]),r[-1]]).toDF(['features','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummy(df,indexCol,categoricalCols,continuousCols,labelCol):\n",
    "\n",
    "    from pyspark.ml import Pipeline\n",
    "    from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "    from pyspark.sql.functions import col\n",
    "\n",
    "    indexers = [ StringIndexer(inputCol=c, outputCol=\"{0}_indexed\".format(c))\n",
    "                 for c in categoricalCols ]\n",
    "\n",
    "    # default setting: dropLast=True\n",
    "    encoders = [ OneHotEncoder(inputCol=indexer.getOutputCol(),\n",
    "                 outputCol=\"{0}_encoded\".format(indexer.getOutputCol()))\n",
    "                 for indexer in indexers ]\n",
    "\n",
    "    assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders]\n",
    "                                + continuousCols, outputCol=\"features\")\n",
    "\n",
    "    pipeline = Pipeline(stages=indexers + encoders + [assembler])\n",
    "\n",
    "    model=pipeline.fit(df)\n",
    "    data = model.transform(df)\n",
    "\n",
    "    data = data.withColumn('label',col(labelCol))\n",
    "\n",
    "    if indexCol:\n",
    "        return data.select(indexCol,'features','label')\n",
    "    else:\n",
    "        return data.select('features','label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|            features|      label|\n",
      "+--------------------+-----------+\n",
      "|[79545.45857,5.68...|1059033.558|\n",
      "|[79248.64245,6.00...|1505890.915|\n",
      "|[61287.06718,5.86...|1058987.988|\n",
      "|[63345.24005,7.18...|1260616.807|\n",
      "|[59982.19723,5.04...|630943.4893|\n",
      "+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Transform the dataset to DataFrame\n",
    "transformed= transData(df)\n",
    "transformed.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "featureIndexer = VectorIndexer(inputCol=\"features\", \\\n",
    "                               outputCol=\"indexedFeatures\",\\\n",
    "                               maxCategories=4).fit(transformed)\n",
    "\n",
    "data = featureIndexer.transform(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+--------------------+\n",
      "|            features|      label|     indexedFeatures|\n",
      "+--------------------+-----------+--------------------+\n",
      "|[79545.45857,5.68...|1059033.558|[79545.45857,5.68...|\n",
      "|[79248.64245,6.00...|1505890.915|[79248.64245,6.00...|\n",
      "|[61287.06718,5.86...|1058987.988|[61287.06718,5.86...|\n",
      "|[63345.24005,7.18...|1260616.807|[63345.24005,7.18...|\n",
      "|[59982.19723,5.04...|630943.4893|[59982.19723,5.04...|\n",
      "+--------------------+-----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "(trainingData, testData) = transformed.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|            features|      label|\n",
      "+--------------------+-----------+\n",
      "|[17796.63119,4.94...| 302355.836|\n",
      "|[35454.71466,6.85...|1077805.578|\n",
      "|[35608.98624,6.93...|449331.5835|\n",
      "|[35797.32312,5.54...|299863.0401|\n",
      "|[35963.33081,3.43...|143027.3645|\n",
      "+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+-----------+\n",
      "|            features|      label|\n",
      "+--------------------+-----------+\n",
      "|[39033.80924,7.67...|1042814.098|\n",
      "|[39294.03652,5.92...|781137.4618|\n",
      "|[39653.77003,5.20...|395901.2501|\n",
      "|[40185.73389,5.94...|529282.0844|\n",
      "|[40503.54133,6.88...|798639.6542|\n",
      "+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainingData.show(5)\n",
    "testData.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LinearRegression class\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain indexer and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[featureIndexer, lr])\n",
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelsummary(model):\n",
    "    import numpy as np\n",
    "    print (\"Note: the last rows are the information for Intercept\")\n",
    "    print (\"##\",\"---------------------------------------------------\")\n",
    "    print (\"##  \",\"  Estimate   |   Std.Error | t Values  |  P-value\")\n",
    "    print (\"##\",\"---------------------------------------------------\")\n",
    "    coef = np.append(list(model.coefficients),model.intercept)\n",
    "    Summary=model.summary\n",
    "\n",
    "    for i in range(len(Summary.pValues)):\n",
    "        print (\"##\",'{:15.6f}'.format(coef[i]),'{:12.6f}'.format(Summary.coefficientStandardErrors[i]),\\\n",
    "        '{:11.3f}'.format(Summary.tValues[i]), \\\n",
    "        '{:12.6f}'.format(Summary.pValues[i]))\n",
    "\n",
    "    print (\"##\",\"---------------------------------------------------\")\n",
    "    print (\"##\",\"Mean squared error: %.6f\" % Summary.meanSquaredError)\n",
    "    print (\"##\",\"RMSE              : %.6f\" % Summary.rootMeanSquaredError )\n",
    "    print (\"##\",\"R-squared         : %f\" % Summary.r2)\n",
    "    print (\"##\",\"Total iterations  : %i\"% Summary.totalIterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: the last rows are the information for Intercept\n",
      "## ---------------------------------------------------\n",
      "##     Estimate   |   Std.Error | t Values  |  P-value\n",
      "## ---------------------------------------------------\n",
      "##       21.508940     0.150804     142.628     0.000000\n",
      "##   166230.977791  1618.070536     102.734     0.000000\n",
      "##   120863.348440  1802.302245      67.061     0.000000\n",
      "##     1393.558373  1470.612058       0.948     0.343388\n",
      "##       15.057466     0.160901      93.582     0.000000\n",
      "## -2631622.177511 19215.351741    -136.954     0.000000\n",
      "## ---------------------------------------------------\n",
      "## Mean squared error: 10189018076.260710\n",
      "## RMSE              : 100940.666118\n",
      "## R-squared         : 0.917533\n",
      "## Total iterations  : 1\n"
     ]
    }
   ],
   "source": [
    "modelsummary(model.stages[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+-----------------+\n",
      "|            features|      label|       prediction|\n",
      "+--------------------+-----------+-----------------+\n",
      "|[39033.80924,7.67...|1042814.098|954379.1942549641|\n",
      "|[39294.03652,5.92...|781137.4618| 575802.915670652|\n",
      "|[39653.77003,5.20...|395901.2501|536412.7485675332|\n",
      "|[40185.73389,5.94...|529282.0844|491420.6038126438|\n",
      "|[40503.54133,6.88...|798639.6542|873850.9818022437|\n",
      "+--------------------+-----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "predictions.select(\"features\",\"label\", \"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.9196741555422578\n"
     ]
    }
   ],
   "source": [
    "y_true = predictions.select(\"label\").toPandas()\n",
    "y_pred = predictions.select(\"prediction\").toPandas()\n",
    "\n",
    "import sklearn.metrics\n",
    "r2_score = sklearn.metrics.r2_score(y_true, y_pred)\n",
    "print('r2_score: {0}'.format(r2_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(maxIter=5, solver=\"l-bfgs\") # solver=\"l-bfgs\" here\n",
    "\n",
    "modelEvaluator=RegressionEvaluator()\n",
    "\n",
    "paramGrid = ParamGridBuilder().addGrid(lr.regParam, [0.1,0.01]).addGrid(lr.elasticNetParam, [0, 1]).build()\n",
    "\n",
    "crossval = CrossValidator(estimator=lr,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=modelEvaluator,\n",
    "                          numFolds=2)\n",
    "\n",
    "cvModel = crossval.fit(trainingData)\n",
    "\n",
    "prediction = cvModel.transform(testData)\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"label\",\n",
    "                                predictionCol=\"prediction\",\n",
    "                                metricName=\"rmse\")\n",
    "\n",
    "rms = evaluator.evaluate(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 101768\n"
     ]
    }
   ],
   "source": [
    "# cvModel uses the best model found from the Cross Validation\n",
    "# Evaluate best model\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "rf = RandomForestRegressor(featuresCol=\"indexedFeatures\",numTrees=10, maxDepth=3, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain indexer and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[featureIndexer, rf])\n",
    "model = pipeline.fit(trainingData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+------------------+\n",
      "|            features|      label|        prediction|\n",
      "+--------------------+-----------+------------------+\n",
      "|[39033.80924,7.67...|1042814.098|1282327.7570918598|\n",
      "|[39294.03652,5.92...|781137.4618|1004550.9205606477|\n",
      "|[39653.77003,5.20...|395901.2501| 1034025.798865634|\n",
      "|[40185.73389,5.94...|529282.0844| 940750.8276492225|\n",
      "|[40503.54133,6.88...|798639.6542| 1231974.741857578|\n",
      "+--------------------+-----------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(testData)\n",
    "# Select example rows to display.\n",
    "predictions.select(\"features\",\"label\", \"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 228886\n"
     ]
    }
   ],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.920\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "r2_score = sklearn.metrics.r2_score(y_true, y_pred)\n",
    "print('r2_score: {:4.3f}'.format(r2_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(5, {0: 0.5077, 1: 0.2502, 2: 0.0736, 3: 0.0055, 4: 0.1629})"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.stages[-1].featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "rf = RandomForestRegressor(labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\\\n",
    "             .addGrid(rf.maxDepth, [2, 6])\\\n",
    "             .addGrid(rf.numTrees, [5, 20])\\\n",
    "             .build())\n",
    "\n",
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=rf, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n",
    "\n",
    "cvModel = cv.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxDepth -  6\n",
      "numTrees -  20\n"
     ]
    }
   ],
   "source": [
    "#BEST HYPERPARAMETERS\n",
    "\n",
    "print('maxDepth - ', cvModel.bestModel._java_obj.getMaxDepth())\n",
    "print('numTrees - ', cvModel.bestModel._java_obj.getNumTrees())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
